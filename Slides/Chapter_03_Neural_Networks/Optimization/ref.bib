@misc{cs231n,
  author       = {Fei-Fei Li and Jiajun Wu and Ruohan Gao},
  title        = {CS231n: Convolutional Neural Networks for Visual Recognition},
  howpublished = {\textit{Lecture slides}},
  institution  = {Stanford University},
  year         = {2022},
  month        = apr,
  note         = {Available: http://cs231n.stanford.edu/slides/2022}
}

@misc{cmu_lecture,
  author       = {Machine learning for signal processing group},
  title        = {11-785 Introduction to Deep Learning},
  howpublished = {\textit{Lecture slides}},
  institution  = {Carnegie Mellon University},
  year         = {2024},
  note         = {Available: https://deeplearning.cs.cmu.edu/F24/document/slides}
}

@misc{mit_6s191_l1,
  author       = {Alexander Amini},
  title        = {6S191: Introduction to Deep Learning},
  howpublished = {\textit{Lecture slides}},
  institution  = {Massachusetts Institute of Technology},
  year         = {2024},
  note         = {Available: http://introtodeeplearning.com/}
}
@misc{ml_explained,
    author = {Anonymous},
    title = {Gradient Descent Explained},
    year = {2021},
    howpublished = {\url{https://ml-explained.com/blog/gradient-descent-explained}},
    note = {Accessed: 2024-10-01}
}

@misc{towardsdatascience,
    author = {Lili Jiang},
    title = {A Visual Explanation of Gradient Descent Methods: Momentum, Adagrad, RMSprop, Adam},
    year = {2021},
    howpublished = {\url{https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c}},
    note = {Accessed: 2024-10-01}
}

@misc{skz_dev,
    author = {Sasha Kuznetsov},
    title = {Gradient Descent},
    year = {2021},
    howpublished = {\url{https://blog.skz.dev/gradient-descent}},
    note = {Accessed: 2024-10-01}
}

@misc{goldstein_loss_landscape,
    author = {Tom Goldstein},
    title = {Loss Landscape},
    year = {2021},
    howpublished = {\url{https://github.com/tomgoldstein/loss-landscape}},
    note = {Accessed: 2024-10-01}
}

@misc{youtube_gradient_descent,
    author = {Grant Sanderson},
    title = {Gradient Descent, Animated},
    year = {2017},
    howpublished = {\url{https://www.youtube.com/watch?v=IHZwWFHWa-w}},
    note = {Accessed: 2024-10-01}
}

@misc{laptrinhx,
    author = {Anonymous},
    title = {Understanding Optimization Algorithms},
    year = {2021},
    howpublished = {\url{https://laptrinhx.com/understanding-optimization-algorithms-3818430905/}},
    note = {Accessed: 2024-10-01}
}

@misc{papers_with_code,
    author = {Anonymous},
    title = {SGD with Momentum},
    year = {2021},
    howpublished = {\url{https://paperswithcode.com/method/sgd-with-momentum}},
    note = {Accessed: 2024-10-01}
}

@misc{wiki_saddle,
    author = {Anonymous},
    title = {Saddle point},
    year = {2024},
    howpublished = {\url{https://en.wikipedia.org/wiki/Saddle_point}},
    note = {Accessed: 2024-10-06}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
